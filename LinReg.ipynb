{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHc2z36vp9Qv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading in Data\n",
        "Diamonds_Train = pd.read_csv('/content/diamonds_train.csv')\n",
        "Diamonds_Test = pd.read_csv('/content/diamonds_test.csv')\n",
        "Diamonds_Val = pd.read_csv('/content/diamonds_val.csv')"
      ],
      "metadata": {
        "id": "mR_NXMc93867"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(split: str):\n",
        "    df = pd.read_csv(f'diamonds_{split}.csv')\n",
        "    df = df.rename(columns = {'Unnamed: 0': 'Index'})\n",
        "    # print(df.dtypes)\n",
        "    x = df.drop(['Index', 'price'], axis = 1) # index col not needed\n",
        "    # print(x.describe())\n",
        "    y = df['price']\n",
        "    # print(y.describe())\n",
        "    # x_arr = x.to_numpy()\n",
        "    # y_arr = y.to_numpy()\n",
        "    # # print(x_arr[1])\n",
        "    # print(y_arr[0])\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "Lww5cRDqqL7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ohe(df: pd.DataFrame, col: str):\n",
        "  '''\n",
        "  One Hot Encodes a Categorical Variable\n",
        "  Arguments:\n",
        "    df: Pandas DataFrame\n",
        "    col: column to encode\n",
        "  Returns:\n",
        "    DataFrame with One Hot Encoded Columns\n",
        "\n",
        "  '''\n",
        "  visited = []\n",
        "  for val in df[col]:\n",
        "    if val not in visited:\n",
        "      visited.append(val)\n",
        "  for val in visited:\n",
        "    if f'{val}_{col}' not in df.columns:\n",
        "      df[f'{val}_{col}'] = df[col].apply(lambda x: 1 if x == val else 0)\n",
        "\n",
        "  df = df.drop(col, axis = 1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "QyINaB-0qPAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(split):\n",
        "  _, y_train = get_data('train')\n",
        "  x_split, y_split = get_data(split)\n",
        "  print(x_split.head())\n",
        "  x_split = ohe(x_split, 'color')\n",
        "  x_split = ohe(x_split, 'cut')\n",
        "  x_split = ohe(x_split, 'clarity')\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(y_train.to_numpy().reshape(-1, 1))\n",
        "  y_split = scaler.transform(y_split.to_numpy().reshape(-1, 1))\n",
        "  n_feats = x_split.shape[1]\n",
        "  print(n_feats)\n",
        "  x_split = x_split.to_numpy()\n",
        "  return x_split, y_split, n_feats\n",
        "\n",
        "# change param to use train as a basis for fit\n"
      ],
      "metadata": {
        "id": "7T3SF4PIraHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, n_feats = feature_engineering('train')\n",
        "x_val, y_val, _  =feature_engineering('val')\n",
        "x_test, y_test, _ = feature_engineering('test')"
      ],
      "metadata": {
        "id": "HZbjXbcdriHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0232375-5126-4a04-c16a-f82161c8738f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   carat        cut color clarity  depth  table     x     y     z\n",
            "0   0.58      Ideal     F     VS1   60.4   57.0  5.42  5.37  3.26\n",
            "1   1.05  Very Good     H     SI1   63.5   57.0  6.47  6.44  4.10\n",
            "2   0.71    Premium     G     SI1   58.9   62.0  5.85  5.79  3.43\n",
            "3   0.50      Ideal     G     VS1   62.0   55.0  5.05  5.11  3.15\n",
            "4   0.52      Ideal     D     VS2   62.3   54.0  5.19  5.14  3.22\n",
            "26\n",
            "   carat        cut color clarity  depth  table     x     y     z\n",
            "0   0.29  Very Good     E     VS1   62.8   44.0  4.20  4.24  2.65\n",
            "1   0.30       Good     G      IF   63.5   55.0  4.26  4.28  2.71\n",
            "2   1.01      Ideal     E     SI1   62.0   57.0  6.38  6.45  3.98\n",
            "3   1.60    Premium     H     VS1   62.5   58.0  7.47  7.37  4.64\n",
            "4   0.78      Ideal     H     VS2   61.6   56.0  5.94  5.91  3.64\n",
            "26\n",
            "   carat        cut color clarity  depth  table     x     y     z\n",
            "0   0.31    Premium     H    VVS2   61.2   60.0  4.39  4.37  2.68\n",
            "1   0.50    Premium     E     VS2   61.8   59.0  5.12  5.08  3.15\n",
            "2   0.72  Very Good     I     VS1   64.0   56.0  5.65  5.73  3.65\n",
            "3   0.70       Good     F     VS2   60.1   56.0  5.73  5.78  3.46\n",
            "4   1.70  Very Good     I     SI1   61.8   58.0  7.55  7.66  4.70\n",
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMW283uFsrAt",
        "outputId": "04c29141-3501-4bbf-8efb-dc50db0644a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.58, 60.4 , 57.  , ...,  0.  ,  0.  ,  0.  ],\n",
              "       [ 1.05, 63.5 , 57.  , ...,  0.  ,  0.  ,  0.  ],\n",
              "       [ 0.71, 58.9 , 62.  , ...,  0.  ,  0.  ,  0.  ],\n",
              "       ...,\n",
              "       [ 0.5 , 62.4 , 53.  , ...,  1.  ,  0.  ,  0.  ],\n",
              "       [ 0.32, 61.9 , 55.  , ...,  0.  ,  0.  ,  0.  ],\n",
              "       [ 1.54, 60.9 , 56.4 , ...,  0.  ,  0.  ,  0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert x_train back to DataFrame and give appropriate column names\n",
        "column_names = ['carat', 'depth', 'table', 'x', 'y', 'z',\n",
        "                'I_color', 'D_color', 'E_color', 'F_color', 'G_color', 'H_color', 'J_color',\n",
        "                'Ideal_cut', 'Premium_cut', 'Very Good_cut', 'Good_cut', 'Fair_cut',\n",
        "                'SI2_clarity', 'SI1_clarity', 'VS1_clarity', 'VS2_clarity', 'VVS2_clarity', 'VVS1_clarity', 'I1_clarity', 'IF_clarity']\n",
        "x_train = pd.DataFrame(x_train, columns=column_names)\n",
        "# Convert y_train back to DataFrame and give appropriate column name\n",
        "column_names = ['price']\n",
        "y_train=pd.DataFrame(y_train, columns=column_names)\n",
        "# Convert x_val back to DataFrame and give appropriate column names\n",
        "column_names = ['carat', 'depth', 'table', 'x', 'y', 'z',\n",
        "                'I_color', 'D_color', 'E_color', 'F_color', 'G_color', 'H_color', 'J_color',\n",
        "                'Ideal_cut', 'Premium_cut', 'Very Good_cut', 'Good_cut', 'Fair_cut',\n",
        "                'SI2_clarity', 'SI1_clarity', 'VS1_clarity', 'VS2_clarity', 'VVS2_clarity', 'VVS1_clarity', 'I1_clarity', 'IF_clarity']\n",
        "x_val = pd.DataFrame(x_val, columns=column_names)\n",
        "# Convert y_val back to DataFrame and give appropriate column name\n",
        "column_names = ['price']\n",
        "y_val=pd.DataFrame(y_val, columns=column_names)\n",
        "# Convert x_test back to DataFrame and give appropriate column names\n",
        "column_names = ['carat', 'depth', 'table', 'x', 'y', 'z',\n",
        "                'I_color', 'D_color', 'E_color', 'F_color', 'G_color', 'H_color', 'J_color',\n",
        "                'Ideal_cut', 'Premium_cut', 'Very Good_cut', 'Good_cut', 'Fair_cut',\n",
        "                'SI2_clarity', 'SI1_clarity', 'VS1_clarity', 'VS2_clarity', 'VVS2_clarity', 'VVS1_clarity', 'I1_clarity', 'IF_clarity']\n",
        "x_test = pd.DataFrame(x_test, columns=column_names)\n",
        "# Convert y_test back to DataFrame and give appropriate column name\n",
        "column_names = ['price']\n",
        "y_test=pd.DataFrame(y_test, columns=column_names)"
      ],
      "metadata": {
        "id": "0sgkjHLi5n7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create linear regression model with carat, x, y and z as predictors, price as response\n",
        "import statsmodels.api as sm\n",
        "X=x_train[['carat', 'x', 'y', 'z']]\n",
        "X = sm.add_constant(X)\n",
        "y=y_train['price']\n",
        "model=sm.OLS(y,X).fit()"
      ],
      "metadata": {
        "id": "QP7OZX9wsriS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the validation error using the validation set and training model\n",
        "X_val=x_val[['carat', 'x', 'y', 'z']]\n",
        "X_val = sm.add_constant(X_val)\n",
        "Y_val=y_val['price']\n",
        "Y_pred=model.predict(X_val)\n",
        "#Show testing error (MSE) on validation set\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse=mean_squared_error(Y_val, Y_pred)\n",
        "print('Validation MSE:', mse)\n",
        "#Show testing error (MSE) on testing set\n",
        "X_test=x_test[['carat', 'x', 'y', 'z']]\n",
        "X_test = sm.add_constant(X_test)\n",
        "Y_test=y_test['price']\n",
        "Y_pred=model.predict(X_test)\n",
        "mse=mean_squared_error(Y_test, Y_pred)\n",
        "print('Testing MSE:', mse)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxp4gjNO4SL9",
        "outputId": "7199012c-1292-4f5a-de96-8304ee676b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 0.1485176082080068\n",
            "Testing MSE: 0.1550386086380108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform forward selection using all predictors\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "predictors =  ['carat', 'depth', 'table', 'x', 'y', 'z', 'I_color', 'D_color', 'E_color', 'F_color', 'G_color', 'H_color', 'J_color',\n",
        "              'Ideal_cut', 'Premium_cut', 'Very Good_cut', 'Good_cut', 'Fair_cut',\n",
        "              'SI2_clarity', 'SI1_clarity', 'VS1_clarity', 'VS2_clarity', 'VVS2_clarity', 'VVS1_clarity', 'I1_clarity', 'IF_clarity']\n",
        "\n",
        "def forward_selection_validation(x_train, y_train, x_val, y_val):\n",
        "    remaining_features = x_train.columns.tolist()\n",
        "    selected_features = []\n",
        "    results = []\n",
        "    best_score = float('inf')\n",
        "    while len(remaining_features) > 0:\n",
        "        scores_with_candidates = []\n",
        "        for feature in remaining_features:\n",
        "            features_subset = selected_features + [feature]\n",
        "            X_train_subset = sm.add_constant(x_train[features_subset])\n",
        "            model = sm.OLS(y_train, X_train_subset).fit()\n",
        "            X_val_subset = sm.add_constant(x_val[features_subset])\n",
        "            y_val_pred = model.predict(X_val_subset)\n",
        "            mse_val = mean_squared_error(y_val, y_val_pred)\n",
        "            scores_with_candidates.append((mse_val, feature, features_subset))\n",
        "        scores_with_candidates.sort()\n",
        "        best_score_candidate, best_feature_to_add, new_features = scores_with_candidates[0]\n",
        "        if best_score_candidate < best_score:\n",
        "              best_score = best_score_candidate\n",
        "              selected_features = new_features\n",
        "              remaining_features.remove(best_feature_to_add)\n",
        "              results.append((best_score, selected_features.copy()))\n",
        "        else:\n",
        "              break\n",
        "    return results\n",
        "\n",
        "# Apply forward selection based on Validation MSE\n",
        "X_train_fs = x_train[predictors]\n",
        "y_train_fs = y_train['price']\n",
        "X_val_fs = x_val[predictors]\n",
        "y_val_fs = y_val['price']\n",
        "\n",
        "results_forward_val = forward_selection_validation(X_train_fs, y_train_fs, X_val_fs, y_val_fs)\n",
        "#Get best model\n",
        "best_mse_forward_val, best_subset_forward_val = results_forward_val[-1]\n",
        "print(\"Best subset by validation MSE (Forward Selection):\", best_subset_forward_val)\n",
        "print(\"Validation MSE (Forward Selection):\", best_mse_forward_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUYuKBXoYcH6",
        "outputId": "26ff44ee-0758-4561-9892-20e8e093345e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best subset by validation MSE (Forward Selection): ['carat', 'IF_clarity', 'J_color', 'x', 'H_color', 'I1_clarity', 'SI2_clarity', 'VVS1_clarity', 'depth', 'table', 'G_color', 'Fair_cut', 'I_color', 'Premium_cut', 'z']\n",
            "Validation MSE (Forward Selection): 0.10620742405563631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create linear regression model\n",
        "import statsmodels.api as sm\n",
        "X=x_train[['carat', 'IF_clarity', 'J_color', 'x', 'H_color', 'I1_clarity', 'SI2_clarity', 'VVS1_clarity', 'depth', 'table', 'G_color', 'Fair_cut', 'I_color', 'Premium_cut', 'z']]\n",
        "X = sm.add_constant(X)\n",
        "y=y_train['price']\n",
        "model=sm.OLS(y,X).fit()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wAbKYreI4Wc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "outputId": "4331e8fd-4a53-4d5d-c744-2d592c658a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                  price   R-squared:                       0.894\n",
              "Model:                            OLS   Adj. R-squared:                  0.894\n",
              "Method:                 Least Squares   F-statistic:                 2.425e+04\n",
              "Date:                Thu, 01 May 2025   Prob (F-statistic):               0.00\n",
              "Time:                        15:09:01   Log-Likelihood:                -12809.\n",
              "No. Observations:               43152   AIC:                         2.565e+04\n",
              "Df Residuals:                   43136   BIC:                         2.579e+04\n",
              "Df Model:                          15                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "================================================================================\n",
              "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
              "--------------------------------------------------------------------------------\n",
              "const            2.0885      0.115     18.237      0.000       1.864       2.313\n",
              "carat            2.8225      0.016    180.133      0.000       2.792       2.853\n",
              "IF_clarity      -0.8991      0.014    -65.045      0.000      -0.926      -0.872\n",
              "J_color         -0.4313      0.007    -58.840      0.000      -0.446      -0.417\n",
              "x               -0.3063      0.009    -34.419      0.000      -0.324      -0.289\n",
              "H_color         -0.2215      0.005    -40.332      0.000      -0.232      -0.211\n",
              "I1_clarity       0.3339      0.009     37.146      0.000       0.316       0.351\n",
              "SI2_clarity      0.1755      0.004     39.410      0.000       0.167       0.184\n",
              "VVS1_clarity     0.2516      0.006     38.739      0.000       0.239       0.264\n",
              "depth           -0.0277      0.001    -20.118      0.000      -0.030      -0.025\n",
              "table           -0.0152      0.001    -19.553      0.000      -0.017      -0.014\n",
              "G_color          0.0637      0.004     14.634      0.000       0.055       0.072\n",
              "Fair_cut        -0.2054      0.010    -20.670      0.000      -0.225      -0.186\n",
              "I_color          0.0585      0.004     13.406      0.000       0.050       0.067\n",
              "Premium_cut     -0.0090      0.004     -2.351      0.019      -0.017      -0.002\n",
              "z               -0.0022      0.010     -0.227      0.820      -0.021       0.017\n",
              "==============================================================================\n",
              "Omnibus:                    12644.235   Durbin-Watson:                   1.996\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           233909.925\n",
              "Skew:                           0.940   Prob(JB):                         0.00\n",
              "Kurtosis:                      14.250   Cond. No.                     6.20e+03\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 6.2e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th> <td>   0.894</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.894</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>2.425e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Thu, 01 May 2025</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>15:09:01</td>     <th>  Log-Likelihood:    </th> <td> -12809.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 43152</td>      <th>  AIC:               </th> <td>2.565e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 43136</td>      <th>  BIC:               </th> <td>2.579e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>        <td>    2.0885</td> <td>    0.115</td> <td>   18.237</td> <td> 0.000</td> <td>    1.864</td> <td>    2.313</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>carat</th>        <td>    2.8225</td> <td>    0.016</td> <td>  180.133</td> <td> 0.000</td> <td>    2.792</td> <td>    2.853</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>IF_clarity</th>   <td>   -0.8991</td> <td>    0.014</td> <td>  -65.045</td> <td> 0.000</td> <td>   -0.926</td> <td>   -0.872</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>J_color</th>      <td>   -0.4313</td> <td>    0.007</td> <td>  -58.840</td> <td> 0.000</td> <td>   -0.446</td> <td>   -0.417</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x</th>            <td>   -0.3063</td> <td>    0.009</td> <td>  -34.419</td> <td> 0.000</td> <td>   -0.324</td> <td>   -0.289</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>H_color</th>      <td>   -0.2215</td> <td>    0.005</td> <td>  -40.332</td> <td> 0.000</td> <td>   -0.232</td> <td>   -0.211</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>I1_clarity</th>   <td>    0.3339</td> <td>    0.009</td> <td>   37.146</td> <td> 0.000</td> <td>    0.316</td> <td>    0.351</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>SI2_clarity</th>  <td>    0.1755</td> <td>    0.004</td> <td>   39.410</td> <td> 0.000</td> <td>    0.167</td> <td>    0.184</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>VVS1_clarity</th> <td>    0.2516</td> <td>    0.006</td> <td>   38.739</td> <td> 0.000</td> <td>    0.239</td> <td>    0.264</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>depth</th>        <td>   -0.0277</td> <td>    0.001</td> <td>  -20.118</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.025</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>table</th>        <td>   -0.0152</td> <td>    0.001</td> <td>  -19.553</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.014</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>G_color</th>      <td>    0.0637</td> <td>    0.004</td> <td>   14.634</td> <td> 0.000</td> <td>    0.055</td> <td>    0.072</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Fair_cut</th>     <td>   -0.2054</td> <td>    0.010</td> <td>  -20.670</td> <td> 0.000</td> <td>   -0.225</td> <td>   -0.186</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>I_color</th>      <td>    0.0585</td> <td>    0.004</td> <td>   13.406</td> <td> 0.000</td> <td>    0.050</td> <td>    0.067</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Premium_cut</th>  <td>   -0.0090</td> <td>    0.004</td> <td>   -2.351</td> <td> 0.019</td> <td>   -0.017</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>z</th>            <td>   -0.0022</td> <td>    0.010</td> <td>   -0.227</td> <td> 0.820</td> <td>   -0.021</td> <td>    0.017</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>12644.235</td> <th>  Durbin-Watson:     </th>  <td>   1.996</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>233909.925</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 0.940</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td>14.250</td>   <th>  Cond. No.          </th>  <td>6.20e+03</td> \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.2e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &      price       & \\textbf{  R-squared:         } &     0.894   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.894   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 2.425e+04   \\\\\n\\textbf{Date:}             & Thu, 01 May 2025 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n\\textbf{Time:}             &     15:09:01     & \\textbf{  Log-Likelihood:    } &   -12809.   \\\\\n\\textbf{No. Observations:} &       43152      & \\textbf{  AIC:               } & 2.565e+04   \\\\\n\\textbf{Df Residuals:}     &       43136      & \\textbf{  BIC:               } & 2.579e+04   \\\\\n\\textbf{Df Model:}         &          15      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                       & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}         &       2.0885  &        0.115     &    18.237  &         0.000        &        1.864    &        2.313     \\\\\n\\textbf{carat}         &       2.8225  &        0.016     &   180.133  &         0.000        &        2.792    &        2.853     \\\\\n\\textbf{IF\\_clarity}   &      -0.8991  &        0.014     &   -65.045  &         0.000        &       -0.926    &       -0.872     \\\\\n\\textbf{J\\_color}      &      -0.4313  &        0.007     &   -58.840  &         0.000        &       -0.446    &       -0.417     \\\\\n\\textbf{x}             &      -0.3063  &        0.009     &   -34.419  &         0.000        &       -0.324    &       -0.289     \\\\\n\\textbf{H\\_color}      &      -0.2215  &        0.005     &   -40.332  &         0.000        &       -0.232    &       -0.211     \\\\\n\\textbf{I1\\_clarity}   &       0.3339  &        0.009     &    37.146  &         0.000        &        0.316    &        0.351     \\\\\n\\textbf{SI2\\_clarity}  &       0.1755  &        0.004     &    39.410  &         0.000        &        0.167    &        0.184     \\\\\n\\textbf{VVS1\\_clarity} &       0.2516  &        0.006     &    38.739  &         0.000        &        0.239    &        0.264     \\\\\n\\textbf{depth}         &      -0.0277  &        0.001     &   -20.118  &         0.000        &       -0.030    &       -0.025     \\\\\n\\textbf{table}         &      -0.0152  &        0.001     &   -19.553  &         0.000        &       -0.017    &       -0.014     \\\\\n\\textbf{G\\_color}      &       0.0637  &        0.004     &    14.634  &         0.000        &        0.055    &        0.072     \\\\\n\\textbf{Fair\\_cut}     &      -0.2054  &        0.010     &   -20.670  &         0.000        &       -0.225    &       -0.186     \\\\\n\\textbf{I\\_color}      &       0.0585  &        0.004     &    13.406  &         0.000        &        0.050    &        0.067     \\\\\n\\textbf{Premium\\_cut}  &      -0.0090  &        0.004     &    -2.351  &         0.019        &       -0.017    &       -0.002     \\\\\n\\textbf{z}             &      -0.0022  &        0.010     &    -0.227  &         0.820        &       -0.021    &        0.017     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 12644.235 & \\textbf{  Durbin-Watson:     } &     1.996   \\\\\n\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 233909.925  \\\\\n\\textbf{Skew:}          &    0.940  & \\textbf{  Prob(JB):          } &      0.00   \\\\\n\\textbf{Kurtosis:}      &   14.250  & \\textbf{  Cond. No.          } &  6.20e+03   \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n [2] The condition number is large, 6.2e+03. This might indicate that there are \\newline\n strong multicollinearity or other numerical problems."
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show MSE of this linear regression model\n",
        "X_val=x_val[['carat', 'IF_clarity', 'J_color', 'x', 'H_color', 'I1_clarity', 'SI2_clarity', 'VVS1_clarity', 'depth', 'table', 'G_color', 'Fair_cut', 'I_color', 'Premium_cut', 'z']]\n",
        "X_val = sm.add_constant(X_val)\n",
        "Y_val=y_val['price']\n",
        "Y_pred=model.predict(X_val)\n",
        "#Show testing error (MSE) on validation set\n",
        "mse=mean_squared_error(Y_val, Y_pred)\n",
        "print('Validation MSE:', mse)\n",
        "#Show error on testing set\n",
        "X_test=x_test[['carat', 'IF_clarity', 'J_color', 'x', 'H_color', 'I1_clarity', 'SI2_clarity', 'VVS1_clarity', 'depth', 'table', 'G_color', 'Fair_cut', 'I_color', 'Premium_cut', 'z']]\n",
        "X_test = sm.add_constant(X_test)\n",
        "Y_test=y_test['price']\n",
        "Y_pred=model.predict(X_test)\n",
        "mse=mean_squared_error(Y_test, Y_pred)\n",
        "print('Testing MSE:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjLgzlowKhzj",
        "outputId": "f753fc34-b42f-4131-ca5d-b3e6d23b33ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 0.10620742405563631\n",
            "Testing MSE: 0.20937723349892412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform ridge regression with my previous linear model\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "ridge_model = Ridge()\n",
        "X=x_train[['carat', 'IF_clarity', 'J_color', 'x', 'H_color', 'I1_clarity', 'SI2_clarity', 'VVS1_clarity', 'depth', 'table', 'G_color', 'Fair_cut', 'I_color', 'Premium_cut', 'z']]\n",
        "X = sm.add_constant(X)\n",
        "param_grid = {'alpha': [0.001, 0.01, 0.1,1,1.3,2, 10, 100]}\n",
        "grid_search = GridSearchCV(ridge_model, param_grid, cv=5)\n",
        "grid_search.fit(X, y_train)\n",
        "best_alpha = grid_search.best_params_['alpha']\n",
        "best_ridge_model = Ridge(alpha=best_alpha)\n",
        "best_ridge_model.fit(X, y_train)\n",
        "#Show results with this model\n",
        "X_val=x_val[['carat', 'IF_clarity', 'J_color', 'x', 'H_color', 'I1_clarity', 'SI2_clarity', 'VVS1_clarity', 'depth', 'table', 'G_color', 'Fair_cut', 'I_color', 'Premium_cut', 'z']]\n",
        "X_val = sm.add_constant(X_val)\n",
        "Y_val=y_val['price']\n",
        "Y_pred=best_ridge_model.predict(X_val)\n",
        "mse=mean_squared_error(Y_val, Y_pred)\n",
        "print('Validation MSE:', mse)\n",
        "#Show best alpha\n",
        "print('Best alpha:', best_alpha)\n",
        "#Show error of model with alpha of 1.3 on testing set\n",
        "X_test=x_test[['carat', 'IF_clarity', 'J_color', 'x', 'H_color', 'I1_clarity', 'SI2_clarity', 'VVS1_clarity', 'depth', 'table', 'G_color', 'Fair_cut', 'I_color', 'Premium_cut', 'z']]\n",
        "X_test = sm.add_constant(X_test)\n",
        "Y_test=y_test['price']\n",
        "Y_pred=best_ridge_model.predict(X_test)\n",
        "mse=mean_squared_error(Y_test, Y_pred)\n",
        "print('Testing MSE:', mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDCjnJNnh-NN",
        "outputId": "cb0b3907-ba9e-40a3-9811-659e5abf2d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 0.10620485897155604\n",
            "Best alpha: 1.3\n",
            "Testing MSE: 0.20911880172820987\n"
          ]
        }
      ]
    }
  ]
}