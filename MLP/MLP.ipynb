{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONwg+N38QsHtzbpeLmJk0/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "cIJo0-X6JSp8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "0rapR0Cy3epq"
      },
      "outputs": [],
      "source": [
        "def get_data(split: str):\n",
        "    df = pd.read_csv(f'diamonds_{split}.csv')\n",
        "    df = df.rename(columns = {'Unnamed: 0': 'Index'})\n",
        "    # print(df.dtypes)\n",
        "    x = df.drop(['Index', 'price'], axis = 1) # index col not needed\n",
        "    # print(x.describe())\n",
        "    y = df['price']\n",
        "    # print(y.describe())\n",
        "    # x_arr = x.to_numpy()\n",
        "    # y_arr = y.to_numpy()\n",
        "    # # print(x_arr[1])\n",
        "    # print(y_arr[0])\n",
        "    return x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ohe(df, col: str):\n",
        "  visited = []\n",
        "  for val in df[col]:\n",
        "    if val not in visited:\n",
        "      visited.append(val)\n",
        "  for val in visited:\n",
        "    if f'{val}_{col}' not in df.columns:\n",
        "      df[f'{val}_{col}'] = df[col].apply(lambda x: 1 if x == val else 0)\n",
        "\n",
        "  df = df.drop(col, axis = 1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "fIErRR0KLg2i"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(split, ):\n",
        "  x, y = get_data(split)\n",
        "  x = ohe(x, 'color')\n",
        "  x = ohe(x, 'cut')\n",
        "  x = ohe(x, 'clarity')\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(y.to_numpy().reshape(-1, 1))\n",
        "  y = scaler.transform(y.to_numpy().reshape(-1, 1))\n",
        "  n_feats = x.shape[1]\n",
        "  # print(n_feats)\n",
        "  x = x.to_numpy()\n",
        "  return x, y, n_feats\n"
      ],
      "metadata": {
        "id": "mA-fBzvbZwIJ"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z: np.ndarray):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def sigmoid(z: np.ndarray):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def tanh(z: np.ndarray | int | float):\n",
        "    res = ((np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z)))\n",
        "    assert np.abs(res - np.tanh(z)) <= 1e-5\n",
        "    return res\n",
        "\n",
        "def half_mse(yhat, y, W: list[np.ndarray], alpha):\n",
        "    y = y.reshape(-1, 1)\n",
        "    yhat = yhat.reshape(-1, 1)\n",
        "\n",
        "    loss = 0.5 * np.mean((y - yhat) ** 2)\n",
        "    reg = (alpha/2)\n",
        "    reg_param = 0\n",
        "    for w in W:\n",
        "        reg_param += (np.sum(w ** 2))\n",
        "    reg *= reg_param\n",
        "    return loss + reg\n",
        "\n",
        "def forward_prop(x, y, W: list[np.ndarray], b: list[np.ndarray], alpha, act_fn):\n",
        "    if len(W) != len(b):\n",
        "        print('unequal amount of weights and biases')\n",
        "        return None\n",
        "\n",
        "    if len(x.shape) == 1:\n",
        "        x = x.reshape(1, -1) # if theres 1 sample\n",
        "\n",
        "    x_col = x.T\n",
        "    # print(f'x col shape: {x_col.shape}')\n",
        "    # print(f'w[0] shape: {W[0].shape}')\n",
        "\n",
        "    z = {}\n",
        "    h = {}\n",
        "\n",
        "    z[0] = W[0] @ x_col + b[0][:, np.newaxis]\n",
        "    h[0] = act_fn(z[0])\n",
        "\n",
        "    for w in range(1, len(W)):\n",
        "        # print(f'Weight at index {w}: {W[w].shape}')\n",
        "        # print(f'activation at index {w-1}: {h[w-1].shape}')\n",
        "        # print(f'bias at index {w}: {b[w].shape}')\n",
        "\n",
        "        z[w] = W[w] @ h[w-1] + b[w][:, np.newaxis]\n",
        "\n",
        "        if w < len(W) - 1 or act_fn == sigmoid:\n",
        "            h[w] = act_fn(z[w])\n",
        "        else:\n",
        "            h[w] = z[w]\n",
        "\n",
        "    # for k, v in z.items():\n",
        "        # print(f'z layer {k}: {v.shape}')\n",
        "    # for k, v in h.items():\n",
        "        # print(f'h layer {k}: {v.shape}')\n",
        "\n",
        "    y_hat = h[len(W) - 1] if len(W) - 1 in h else z[len(W) - 1]\n",
        "    # print(f'y_hat shape: {y_hat.shape}')\n",
        "\n",
        "    if len(y.shape) == 1:\n",
        "        y = y.reshape(-1, 1)\n",
        "\n",
        "    loss = half_mse(y_hat, y, W, alpha)\n",
        "\n",
        "    return loss, z, h, x, y_hat\n",
        "\n",
        "def back_prop(X, y, W: list[np.ndarray], B: list[np.ndarray], alpha, act_fn):\n",
        "    if len(X.shape) == 1:\n",
        "        X = X.reshape(1, -1)\n",
        "    loss, z, h, x, yhat = forward_prop(X, y, W, B, alpha, act_fn)\n",
        "\n",
        "    if len(y.shape) == 1:\n",
        "        y = y.reshape(-1, 1)\n",
        "    dW = []\n",
        "    dB = []\n",
        "    n_layers = len(W)\n",
        "\n",
        "    delta = None\n",
        "    for i in range(n_layers - 1, -1, -1):\n",
        "\n",
        "        if i == n_layers - 1:\n",
        "            delta = -(y - yhat.T).T\n",
        "        else:\n",
        "            if act_fn == relu:\n",
        "                delta = (W[i+1].T @ delta) * (z[i] > 0)\n",
        "            elif act_fn == sigmoid:\n",
        "                delta = (W[i+1].T @ delta) * (h[i] * (1 - h[i]))\n",
        "            elif act_fn == tanh:\n",
        "                delta = (W[i+1].T @ delta) * (1 - h[i]**2)\n",
        "            else:\n",
        "                print('Unsupported activation function')\n",
        "                return None\n",
        "\n",
        "        if i > 0:\n",
        "            dW_i = delta @ h[i-1].T / X.shape[0]\n",
        "        else:\n",
        "            dW_i = delta @ X / X.shape[0]\n",
        "\n",
        "        dB_i = np.mean(delta, axis=1)\n",
        "\n",
        "        dW_i = dW_i + alpha * W[i]\n",
        "\n",
        "        dW.insert(0, dW_i)\n",
        "        dB.insert(0, dB_i)\n",
        "\n",
        "    return dW, dB, loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train(x_train: np.ndarray, y_train: np.ndarray, W: list[np.ndarray], b: list[np.ndarray],\n",
        "          learning_rate=1e-3, batch_size=32, num_epochs=100, reg_param=1e-4, clip_val=1.0, act_fn=relu, tol: float = 0.001, min_iter = 10):\n",
        "    losses = []\n",
        "    # print(f\"Number of weight matrices: {len(W)}\")\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0\n",
        "        idx = np.random.permutation(x_train.shape[0])\n",
        "        x_train_shuffled, y_train_shuffled = x_train[idx], y_train[idx]\n",
        "\n",
        "        for i in range(0, x_train.shape[0], batch_size):\n",
        "            batch_x = x_train_shuffled[i:i+batch_size]\n",
        "            batch_y = y_train_shuffled[i:i+batch_size]\n",
        "\n",
        "            # print(f\"Batch x shape: {batch_x.shape}\")\n",
        "\n",
        "\n",
        "            dW, dB, loss = back_prop(batch_x, batch_y, W, b, reg_param, act_fn)\n",
        "\n",
        "            # print(f\"Number of dW matrices: {len(dW)}\")\n",
        "            # print(f\"Number of dB vectors: {len(dB)}\")\n",
        "\n",
        "            for j in range(len(W)):\n",
        "                W[j] -= learning_rate * np.clip(dW[j], -clip_val, clip_val)\n",
        "                b[j] -= learning_rate * np.clip(dB[j], -clip_val, clip_val)\n",
        "\n",
        "            epoch_loss += loss\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / (x_train.shape[0] // batch_size + 1)\n",
        "        losses.append(avg_epoch_loss)\n",
        "        if np.abs(losses [epoch] - losses [epoch - 1]) < tol and epoch > min_iter:\n",
        "          # print (f'{losses [epoch] - losses [epoch - 1]}')\n",
        "          print(f\"Epoch {epoch+1}, Loss: {avg_epoch_loss}\")\n",
        "          print(f'Stopped early because {losses[epoch]} and {losses[epoch-1]} are too similar', )\n",
        "          return losses, W, b\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {avg_epoch_loss}\")\n",
        "\n",
        "    return losses, W, b\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OkvkEkpMFTjb"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    x_train, y_train, n_feats = feature_engineering('train')\n",
        "\n",
        "\n",
        "    n_hidden = 64\n",
        "    n_out = 1\n",
        "\n",
        "    W1 = np.random.randn(n_hidden, n_feats) * 0.01\n",
        "    b1 = np.zeros(n_hidden)\n",
        "    W2 = np.random.randn(n_hidden, n_hidden) * 0.01\n",
        "    b2 = np.zeros(n_hidden)\n",
        "    W3 = np.random.randn(n_out, n_hidden) * 0.01\n",
        "    b3 = np.zeros(n_out)\n",
        "    losses, W, B = train(x_train, y_train, [W1, W2, W3], [b1, b2, b3])\n",
        "    print(f'final train loss: {losses[-1]}')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTWA0W1aSv5Q",
        "outputId": "3fb0121d-7818-4ba1-b248-97c58b5ac4af"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:00<00:51,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4998936623509926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:01<00:50,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 0.49945976557624505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:01<00:48,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 0.4990022866925625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:02<00:48,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 0.49805005367861926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:02<00:47,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 0.49551354088177096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:03<00:47,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 0.4865900997527618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:03<00:46,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 0.43988562834448924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:04<00:46,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 0.2230152649317836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:04<00:45,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 0.12070616039775842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:05<00:45,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.11166615308993681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:05<00:44,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 0.10772767166430991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:06<00:44,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 0.10193913713995627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:06<00:43,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 0.093875825872608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:07<00:43,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 0.08853997283804835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:07<00:42,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 0.08446112369051621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:08<00:41,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 0.08029393227023095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:08<00:41,  2.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 0.07724912886654105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:08<00:40,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 0.07500319135431527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:09<00:39,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 0.07176615848645222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:09<00:39,  2.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.06968112147076234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:10<00:44,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 0.06855965791862212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:11<00:48,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Loss: 0.06621738249540224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:12<00:43,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Loss: 0.06540766440941635\n",
            "Stopped early because 0.06540766440941635 and 0.06621738249540224 are too similar\n",
            "final train loss: 0.06540766440941635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_val, y_val, val_n = feature_engineering('val')\n",
        "learning_rate=1e-3\n",
        "\n",
        "pred  = forward_prop(x_val, y_val, W, B , alpha = learning_rate, act_fn = relu)\n",
        "\n",
        "print(f'performance (loss wise) on the validation data: {pred[0]:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MUH6CNxWyiG",
        "outputId": "dc1f9658-80c4-453f-89f8-e1bddb9d2db8"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "performance (loss wise) on the validation data: 0.0803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(y_val)\n",
        "print(n)\n",
        "\n",
        "aic_val = n * np.log(pred[0]) + 2 * val_n\n",
        "bic_val = n * np.log(pred[0]) + val_n * np.log(n)\n",
        "print('Validation AIC:', aic_val)\n",
        "print('Validation BIC:', bic_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F82F0hg6WyuI",
        "outputId": "9e315557-3bac-4f33-cb6e-b53dd71c220e"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5394\n",
            "Validation AIC: -13549.221758676178\n",
            "Validation BIC: -13377.802653579987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST TO COME ..."
      ],
      "metadata": {
        "id": "a4tV1McMeKlA"
      }
    }
  ]
}